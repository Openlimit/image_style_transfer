## 实现论文
### Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks


## 项目依赖
1. python: 3.6.5
2. pytorch: 0.4.0
3. python库：scipy, numpy, argparse

## 实验流程
#### 1. 训练： python train.py --xpath xxxx --ypath xxxx --size 128|256
   1. --xpath: 一种风格的图片集地址
   2. --ypath: 另一种风格的图片集地址
   3. --size: 图片大小，128或者256
#### 2. 测试：python val.py --image_path xxxx --out_path xxxx --size 128|256 --type photo2anime|anime2photo|photo2monet|monet2photo
   1. --image_path: 待测试的图片地址
   2. --out_path: 输出地址
   3. --size: 图片大小，128或者256
   4. --type: 风格转换类型，已训练的模型包括photo2anime，anime2photo，photo2monet，monet2photo


## 实验细节
1. 网络结构： 与原论文相同
2. 训练参数： batch size为1, 采用Adam优化，初始learning rate为0.0002，训练epoch数为200
3. 图片数据增强： 使用了裁剪，水平翻转和颜色抖动


## 实验结果
实验结果放在test文件夹下，预训练模型在pretrained_model文件夹下

#### 1. 真实人脸 to 动画人脸：
![image](./test/photo2anime/real_1.jpg)
![image](./test/photo2anime/fake_1.jpg)

![image](./test/photo2anime/real_2.jpg)
![image](./test/photo2anime/fake_2.jpg)

#### 2. 动画人脸 to 真实人脸：效果较差
![image](./test/anime2photo/real_1.png)
![image](./test/anime2photo/fake_1.jpg)

![image](./test/anime2photo/real_2.png)
![image](./test/anime2photo/fake_2.jpg)


#### 3. 真实图片 to monet画作：
![image](./test/photo2monet/real_1.jpg)
![image](./test/photo2monet/fake_1.jpg)

![image](./test/photo2monet/real_2.jpg)
![image](./test/photo2monet/fake_2.jpg)


#### 4. monet画作 to 真实图片：
![image](./test/monet2photo/real_1.jpg)
![image](./test/monet2photo/fake_1.jpg)

![image](./test/monet2photo/real_2.jpg)
![image](./test/monet2photo/fake_2.jpg)